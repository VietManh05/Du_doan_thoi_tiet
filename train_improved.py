import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
import os
import numpy as np

IMAGE_SIZE = (224, 224)
BATCH_SIZE = 32
EPOCHS = 15
NUM_CLASSES = 3

print("\n" + "="*60)
print("üöÄ TRAINING MODEL C√ì C·∫¢I THI·ªÜN")
print("="*60)

# B∆∞·ªõc 1: T√≠nh class weights ƒë·ªÉ c√¢n b·∫±ng
print("\nüìä B∆∞·ªõc 1: T√≠nh class weights")
from pathlib import Path

class_counts = {}
data_path = Path('data')
for class_name in ['M∆∞a', 'N·∫Øng', 'Tuy·∫øt']:
    count = len(list((data_path / class_name).glob('*.[jJ][pP]*[gG]')))
    class_counts[class_name] = count
    print(f"   {class_name}: {count} ·∫£nh")

total_samples = sum(class_counts.values())
class_weights = {}
for i, class_name in enumerate(['M∆∞a', 'N·∫Øng', 'Tuy·∫øt']):
    weight = total_samples / (NUM_CLASSES * class_counts[class_name])
    class_weights[i] = weight
    print(f"   Weight cho {class_name}: {weight:.2f}")

# B∆∞·ªõc 2: Chu·∫©n b·ªã d·ªØ li·ªáu v·ªõi augmentation m·∫°nh h∆°n
print("\nüñºÔ∏è  B∆∞·ªõc 2: Chu·∫©n b·ªã d·ªØ li·ªáu")

data_gen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
    rotation_range=30,          # TƒÉng t·ª´ 20 l√™n 30
    horizontal_flip=True,
    vertical_flip=True,         # Th√™m flip d·ªçc
    brightness_range=[0.7, 1.3],  # TƒÉng range
    width_shift_range=0.2,      # Th√™m shift
    height_shift_range=0.2,
    shear_range=0.2,            # Th√™m shear
    zoom_range=0.2,             # Th√™m zoom
    fill_mode='nearest'
)

train_gen = data_gen.flow_from_directory(
    'data',
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training',
    shuffle=True
)

valid_gen = data_gen.flow_from_directory(
    'data',
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation',
    shuffle=False
)

print(f"   Training: {train_gen.samples} ·∫£nh")
print(f"   Validation: {valid_gen.samples} ·∫£nh")

# B∆∞·ªõc 3: X√¢y d·ª±ng model c·∫£i thi·ªán
print("\nüèóÔ∏è  B∆∞·ªõc 3: X√¢y d·ª±ng model")

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),
    BatchNormalization(),
    Conv2D(32, (3, 3), activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D((2, 2)),
    Dropout(0.25),
    
    Conv2D(64, (3, 3), activation='relu', padding='same'),
    BatchNormalization(),
    Conv2D(64, (3, 3), activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D((2, 2)),
    Dropout(0.25),
    
    Conv2D(128, (3, 3), activation='relu', padding='same'),
    BatchNormalization(),
    Conv2D(128, (3, 3), activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D((2, 2)),
    Dropout(0.25),
    
    Flatten(),
    Dense(256, activation='relu'),
    BatchNormalization(),
    Dropout(0.5),
    Dense(128, activation='relu'),
    BatchNormalization(),
    Dropout(0.3),
    Dense(NUM_CLASSES, activation='softmax')
])

# Compile v·ªõi learning rate th·∫•p h∆°n
optimizer = Adam(learning_rate=0.0001)
model.compile(
    optimizer=optimizer,
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

print("   Model architecture:")
model.summary()

# B∆∞·ªõc 4: Training v·ªõi class weights
print("\n‚öôÔ∏è  B∆∞·ªõc 4: Training model")

checkpoint = tf.keras.callbacks.ModelCheckpoint(
    'checkpoints/simple_model_best.h5',
    monitor='val_accuracy',
    save_best_only=True,
    mode='max',
    verbose=1
)

early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_accuracy',
    patience=3,
    restore_best_weights=True,
    verbose=1
)

# QUAN TR·ªåNG: S·ª≠ d·ª•ng class_weights
history = model.fit(
    train_gen,
    validation_data=valid_gen,
    epochs=EPOCHS,
    class_weight=class_weights,  # ‚Üê KEY LINE
    callbacks=[checkpoint, early_stopping],
    verbose=1
)

model.save('checkpoints/simple_model.h5')

# B∆∞·ªõc 5: K·∫øt qu·∫£
print("\n" + "="*60)
print("‚úÖ HO√ÄN TH√ÄNH TRAINING")
print("="*60)
print(f"\nüìà K·∫øt qu·∫£:")
print(f"   Accuracy cao nh·∫•t (training): {max(history.history['accuracy']):.2%}")
print(f"   Accuracy cao nh·∫•t (validation): {max(history.history['val_accuracy']):.2%}")
print(f"\nüíæ Model ƒë√£ l∆∞u:")
print(f"   ‚Ä¢ checkpoints/simple_model_best.h5")
print(f"   ‚Ä¢ checkpoints/simple_model.h5")

print(f"\nüéØ C·∫£i thi·ªán:")
print(f"   ‚úÖ S·ª≠ d·ª•ng class_weight ƒë·ªÉ c√¢n b·∫±ng d·ªØ li·ªáu")
print(f"   ‚úÖ TƒÉng data augmentation (30 ƒë·ªô rotation, zoom, shift, shear)")
print(f"   ‚úÖ Th√™m Batch Normalization")
print(f"   ‚úÖ TƒÉng Dropout (l√™n 0.5)")
print(f"   ‚úÖ Gi·∫£m learning rate (0.0001)")
